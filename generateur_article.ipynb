{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un générérateur d'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'avoir un programme qui génére des articles de façon aléatoire. Pour cela, il analyse dans des textes la fréquences des mots qui se suivent.\n",
    "Pour l'entrainer, les textes seront issus de wikipedia francophone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoir un corpus de texte, extraction de wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer avec l'aide de chat-GPT.\n",
    "Il s'agit de sélectionner des article de la wikipedia française (par défaut) et d'en prendre le texte sans les mises en forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'articles à extraire\n",
    "# Attention, minimum 2 \n",
    "nombre_articles_a_extraire = 2\n",
    "\n",
    "# Où les sauver\n",
    "chemin_extraction =  \"./vrai_texte/wikipedia/\"\n",
    "\n",
    "# Choix de la version linguistique \n",
    "langue = \"fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le code d'extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Pentamètre iambique ajouté\n",
      "Article Gare de l'Université Hadj Lakhdar ajouté\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "\n",
    "# Définir la langue\n",
    "wikipedia.set_lang(langue)  \n",
    "\n",
    "try:\n",
    "    # Obtenir une liste aléatoire de titres d'articles\n",
    "    titles = wikipedia.random(nombre_articles_a_extraire)\n",
    "\n",
    "    # Pour chaque article, extraire le contenu et enregistrer dans un fichier\n",
    "    for title in titles:\n",
    "        # Obtenir le contenu de l'article\n",
    "        content = wikipedia.page(title).content\n",
    "        \n",
    "        # Supprimer les signes == ou === et double saut de ligne du contenu\n",
    "        content = content.replace(\"===\", \"\")\n",
    "        content = content.replace(\"==\", \"\")\n",
    "        content = content.replace(\"\\n\\n\", \"\")\n",
    "            \n",
    "        # Créer un fichier avec le titre de l'article comme nom\n",
    "        file_name = chemin_extraction + title + \".txt\"\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        print(f\"\"\"Article {title} ajouté\"\"\")\n",
    "except:\n",
    "    print(f\"\"\"l'article {title} génére une erreur\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gérer les fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se simplifier la vie (ou pas), tout ce qui touche à l'ouverture de fichiers, lecture, écriture est regroupé dans une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestionfichier():\n",
    "    \"\"\"classe pour gérer les dossiers et fichiers\"\"\"\n",
    "    \n",
    "    def lister_fichier(self, source : str)-> list:\n",
    "        \"\"\"pour tous les fichiers du dossier, \n",
    "        on fait confiance qu'il ne s'agit que d'un texte,\n",
    "        mettre tous les noms dans une liste\n",
    "        arg\n",
    "        - source (str) : chemin du dossier\n",
    "        return\n",
    "        - tousleschemins(liste) : liste avec les nom des image dans la source\n",
    "        \"\"\"\n",
    "        tousleschemins: list = []\n",
    "        for fichier in os.listdir(source):\n",
    "            tousleschemins.append(\"vrai_texte/wikipedia/\" + fichier)\n",
    "        return tousleschemins\n",
    "\n",
    " \n",
    "    def lirefichier(self, chemin: str)-> str:\n",
    "        \"\"\"ouvre un fichier et transfert son contenue dans une chaine\n",
    "        arg\n",
    "        - chemin (str) : chemin du dossier\n",
    "        return\n",
    "        - contenu_du_fichier (str) : le contenu du fichier\"\"\"\n",
    "        fichier = open(chemin, 'r')\n",
    "        contenu_du_fichier: str = fichier.read()\n",
    "        return contenu_du_fichier\n",
    "    \n",
    "    \n",
    "    def ecrirefichier(self, nom, contenu)->None:\n",
    "        \"\"\"ecrit un chaine dans un fichier\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## la classe Article_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_source():\n",
    "    \"\"\"chaque article qui servira d'entrée en apprentissage sera mis dans un objet pour analyse, extraction...\"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            une chaine de texte (si possible longue)\n",
    "        return :\n",
    "            aucun\n",
    "        \"\"\"\n",
    "        self.texte:str = text #le texte sur lequel on travail\n",
    "        self.dicostatique:dict = {} #pour la fonction liste_et_compte_mots\n",
    "        self.dicodoublons:dict = {} #pour la fonction cherche_binomes_mots - ce qui est recherché\n",
    "    \n",
    "    def retirer_ponctuation(self, txt_a_nettoyer:str) -> str:\n",
    "        \"\"\" La première version du logiciel est sommaire. \n",
    "        Pour se simplifier la vie, il faut supprimer tous les signe de ponctuations.\n",
    "        arg:\n",
    "            une chaine de texte avec de la ponctuation\n",
    "        return:\n",
    "            une chaine de texte sans ponctuation\n",
    "        \"\"\"\n",
    "        ponctuation : list = [\",\",\";\",\":\",\"!\",\"?\",\".\",\"/\",\"«\",\"»\",'\"',\"–\",\"(\",\")\"]\n",
    "        for signe in ponctuation:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(signe, \"\")\n",
    "        #mettre un espace entre les mots avec apostrophe afin de bien les séparer\n",
    "        apostrophe = [\"’\",\"'\"]\n",
    "        for apost in apostrophe:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(apost, \" \")\n",
    "        #quand on supprime un : par exemple, cela fait deux espace. Remplacer ces artefacts de cagage\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\"  \", \" \")\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\" \", \" \")\n",
    "        return txt_a_nettoyer\n",
    "\n",
    "    def liste_et_compte_mots(self, texte_a_traiter:str) -> list[list,dict]:\n",
    "        \"\"\"Compte le nombre d'occurence d'un mot.\n",
    "        Fonction créée un peu par erreur, mais elle peut être utile pour faire des statistiques.\n",
    "        arg : \n",
    "            texte_a_traiter (str)\n",
    "        return : \n",
    "            2 object dans un liste. La liste des mots de la chaine et le comptrage de chaque mot dans un dictionnaire\n",
    "            \"\"\"\n",
    "        liste_mot: list[str] = texte_a_traiter.split(\" \")\n",
    "        dicostatistique = {}\n",
    "        for mot in liste_mot:\n",
    "            if mot in dicostatistique:\n",
    "                dicostatistique[mot] += 1\n",
    "            else:\n",
    "                dicostatistique[mot] = 1\n",
    "        return [liste_mot, dicostatistique]\n",
    "    \n",
    "    def cherche_binomes_mots(self, texte_a_traiter:str) -> dict:\n",
    "        \"\"\"la fonction principale de l'objet : faire un dictionnaire de fréquences des mots qui se suivent. \n",
    "        arg :\n",
    "            self\n",
    "        return :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "        \"\"\"\n",
    "        liste_mots_suivant:list = []\n",
    "        dicodoublons:dict = {}\n",
    "        #recherche des espaces délimitants les mots\n",
    "        list_position_espace = []\n",
    "        for i in range(len(texte_a_traiter)):\n",
    "            if texte_a_traiter[i] == \" \":\n",
    "                list_position_espace.append(i)\n",
    "        #print(list_position_espace)\n",
    "        #recherche doublons mot\n",
    "        debut1 = 0\n",
    "        for i in range(len(list_position_espace)-2): #AFAIRE : ATTENTION ça ne prends pas les deux derniers mot. A vérifier.\n",
    "            fin1 = list_position_espace[i]\n",
    "            fin2 = list_position_espace[i + 1]\n",
    "            #print(debut1, fin1,fin2)\n",
    "            mot1 = texte_a_traiter[debut1:fin1]\n",
    "            mot2 = texte_a_traiter[fin1:fin2]\n",
    "            debut1 = list_position_espace[i]\n",
    "            #print(mot1,mot2)\n",
    "            liste_mots_suivant.append([mot1, mot2])\n",
    "        #print(liste_mots_suivant)\n",
    "        #fait un dictionnaire avec toutes les occurences possible après un même mot.\n",
    "        #les doublons sont normaux, cela veut dire que le mot revient plusieurs fois, cela correspond au calcul de leur fréquence   \n",
    "        for j in range(len(liste_mots_suivant)):\n",
    "            if liste_mots_suivant[j][0] in dicodoublons.keys():\n",
    "                #print('doublons')\n",
    "                dicodoublons[liste_mots_suivant[j][0]].append(liste_mots_suivant[j][1])\n",
    "            else:\n",
    "                #print('nouveau')\n",
    "                dicodoublons[liste_mots_suivant[j][0]]=[(liste_mots_suivant[j][1])]\n",
    "        # Warning : il y a des espace en trop (tenu en compte pour le reste et tests)\n",
    "        return dicodoublons \n",
    "    \n",
    "    def tout_enchainer(self) -> dict :\n",
    "        self.texte = self.retirer_ponctuation(self.texte)\n",
    "        #self.dicostatique = self.liste_et_compte_mots(self.texte)[1]\n",
    "        #print(self.dicostatique)\n",
    "        #print(\"--------------\")\n",
    "        dicodoublons_txt = self.cherche_binomes_mots(self.texte)\n",
    "        return dicodoublons_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester les méthodes de la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import Mock, patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_analyse():\n",
    "    \n",
    "    def test_retirer_ponctuation(self):\n",
    "        chaine = \"Le, petit chat d'Hercule est mort !\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        retirer = textdebase.retirer_ponctuation(chaine)\n",
    "        assert retirer == \"Le petit chat d Hercule est mort \"\n",
    "        \n",
    "    def test_liste_et_compte_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        list_mot = textdebase.liste_et_compte_mots(chaine)[0]\n",
    "        dico_mot = textdebase.liste_et_compte_mots(chaine)[1]\n",
    "        assert list_mot == ['le','petit','chat','de','béatrice','est','sur','le','petit','mur','du','jardin','de','Yves']\n",
    "        assert dico_mot == {'le':2,'petit':2,'chat':1,'de':2,'béatrice':1,'est':1,'sur':1,'mur':1,'du':1,'jardin':1,'Yves':1}\n",
    "     \n",
    "    \"\"\"   \n",
    "    def test_cherche_binomes_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        dico = textdebase.cherche_binomes_mots(chaine)\n",
    "        assert dico == {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeur = Test_modele_analyse()\n",
    "testeur.test_retirer_ponctuation()\n",
    "testeur.test_liste_et_compte_mots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_au_hasard():\n",
    "    \"\"\"génére un texte aléatoire à partir d'un dictionnaire\n",
    "    \n",
    "        arg :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "            typiquement le dictionnaire généré par le return de cherche_binomes_mots(), ou d'une sauvegarde issus de cette fonction.\n",
    "        \n",
    "        return\n",
    "            une chaine de texte avec les mots du dictionnaire dans un ordre aléatoire.\n",
    "            elle pourra aller dans un doc txt pour sauvegarde\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mondico:dict):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            mondico (dict) : pour chaque mot en cle dedans, il y a une liste de mot possible.\n",
    "        \"\"\"\n",
    "        self.mondico: dict = mondico #le dictionnaire sur lequel on travail\n",
    "        self.textealeatoire : str =\"\" #le texte que l'on veut\n",
    "    \n",
    "    def choixmotpourcommencer(self, dico: dict)-> str:\n",
    "        \"\"\"a utiliser pour le premier mot, \n",
    "        mais aussi si un mot ne peut pas en trouver d'autre, faire une proposition pour eviter une erreur et continuer\n",
    "        \"\"\"\n",
    "        #Mettre les clefs dans une liste\n",
    "        liste_des_mots : list = []\n",
    "        for key in dico:\n",
    "            liste_des_mots.append(key)\n",
    "        #choix lui meme\n",
    "        mot: str = liste_des_mots[random.randint(0, len(liste_des_mots))]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "\n",
    "    def chercherlemotsuivant(self, dico: dict, mot: str) -> str:\n",
    "        \"\"\"à partir d'un mot, sortir aléatoire un mot dans ceux pouvant le suivre stocké dans le dictionnaire\"\"\"\n",
    "        liste_des_possible: list = dico[\" \" + mot] #WARNING on remet un espace car dans la version du moment, il y a un espace dans le dico et c'est pas bien\n",
    "        mot: str = liste_des_possible[random.randint(0, len(liste_des_possible) -1 )]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "    \n",
    "    def genereruntexte(self, taille_article: int) -> None:\n",
    "        \"\"\"intier avec choixmotpourcommencer(), puis enchainer chercherlemotsuivant()\n",
    "        taille_article est le nombre de mot que l'on veut pour l'article aléatoire\n",
    "        \"\"\"\n",
    "        mot: str = self.choixmotpourcommencer(self.mondico)\n",
    "        self.textealeatoire += mot\n",
    "        for _ in range(taille_article - 1):\n",
    "            new_mot: str = self.chercherlemotsuivant(self.mondico, mot)\n",
    "            mot = new_mot\n",
    "            self.textealeatoire = self.textealeatoire + \" \" + mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester la class Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_generation():\n",
    "    \n",
    "    def test_choixmotpourcommencer(self, mocker):\n",
    "        dictionnaire = {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "        mocker.patch('random.randint', return_value=1)\n",
    "        generation = Article_au_hasard(dictionnaire)\n",
    "        generation.mot = generation.choixmotpourcommencer(dictionnaire)\n",
    "        assert generation.mot == \"petit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'patch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m testeur_article \u001b[38;5;241m=\u001b[39m Test_modele_generation()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtesteur_article\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_choixmotpourcommencer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m, in \u001b[0;36mTest_modele_generation.test_choixmotpourcommencer\u001b[0;34m(self, mocker)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_choixmotpourcommencer\u001b[39m(\u001b[38;5;28mself\u001b[39m, mocker):\n\u001b[1;32m      4\u001b[0m     dictionnaire \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mmocker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom.randint\u001b[39m\u001b[38;5;124m'\u001b[39m, return_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     generation \u001b[38;5;241m=\u001b[39m Article_au_hasard(dictionnaire)\n\u001b[1;32m      8\u001b[0m     generation\u001b[38;5;241m.\u001b[39mmot \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mchoixmotpourcommencer(dictionnaire)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'patch'"
     ]
    }
   ],
   "source": [
    "testeur_article = Test_modele_generation()\n",
    "testeur_article.test_choixmotpourcommencer(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additioner des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_dico(grand_dico : dict, petit_dico : dict)-> dict:\n",
    "    \"\"\"Permet de mettre le contenu d'un dictionnaire dans un autre.\n",
    "    Si dans les deux dic, il y a une clef commune, il concatène les deux listes de mot\"\"\"\n",
    "    for keys, values in petit_dico.items():\n",
    "        if keys in grand_dico:\n",
    "            liste_intermediaire = grand_dico[keys]\n",
    "            for item in values:\n",
    "                liste_intermediaire.append(item)\n",
    "            grand_dico[keys] = liste_intermediaire\n",
    "        else:\n",
    "            grand_dico[keys] = values\n",
    "    return grand_dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tester l'addition de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_addition_dico():\n",
    "    dico1 = {'a' : ['le', 'petit'], 'b' : ['chat', 'de']}\n",
    "    dico2 = {'b' : ['de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    dico3 = addition_dico(dico1, dico2)\n",
    "    assert dico3 == {'a' : ['le', 'petit'], 'b' : ['chat', 'de', 'de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    \n",
    "test_addition_dico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser tous les fichiers d'un dossier et en faire un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_dossier_et_faire_dico(source : str) -> dict:\n",
    "    \"\"\"Pour tous les fichiers d'un dossier, \n",
    "    lire le contenue, en faire le dictionnaire \n",
    "    et fusionner tous les dictionnaire en un seul.\n",
    "    arg:\n",
    "    - source (str) : chemin d'un dossier\n",
    "    return:\n",
    "    - dict_statistique (dict)\n",
    "    \"\"\"\n",
    "    gestionnaire =Gestionfichier()\n",
    "    lesfichichiers = gestionnaire.lister_fichier(source)\n",
    "    #print(lesfichichiers)\n",
    "    dict_statistique = {}\n",
    "    for item in lesfichichiers:\n",
    "        contenu_a_analyser = gestionnaire.lirefichier(item)\n",
    "        analyseur = Article_source(contenu_a_analyser)\n",
    "        dico_item = analyseur.tout_enchainer()\n",
    "        dict_statistique = addition_dico(dict_statistique, dico_item)\n",
    "    return dict_statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfin, générer notre article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des fichiers de 'vrai_texte/wikipedia', génére un texte de 250 mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou_sont_les_sources = \"vrai_texte/wikipedia\"\n",
    "nb_mot_article = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer le dictionnaire qui pourra être réutilisé plusieurs fois\n",
    "superdico = analyser_dossier_et_faire_dico(ou_sont_les_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Society Ces éléments répond à l inscription au Congrès mondial pas fixe personne au printemps 1773 à Londres le domaine technique de France galerie Inard Gromaire été\n",
      "1972 Ivry-sur-Seine salle du dessin ou ménagers les personnes qui peut être indéfiniment D ailleurs encore suivie par Google\n",
      " Introduction \n",
      "Les habitants La forme actuelle 1950 pour leur rôle de mystères Au match annuel En ce qui précédaient les gardiens pompiers… et symphonique de l ancienne est cependant rapidement à l auteur =Le droit d un jardinier et le défaut en Europe L esthétique d impôt pendant une biographie de la 1re éd Sipayat collection Études littéraires et les experts datent le Weekly Morning Après avis du Parti en hanyu pinyin é › et Soukhoï Su-2 et la compétition\n",
      " Biographie \n",
      "Charles Textor est demandé l un lien connu au sport automobile Maserati ainsi les contextes écopaysagers Par exemple le FP7 L année Les autorités judiciaires et étendues de Chicago États-Unis Le chêne [réf nécessaire]\n",
      " Œuvres \n",
      "la force dans le fichier policier André Breton et se remet à la liberté Péché véniel péché mortel et l INRA au Parlement et en plaine du Songe du temps et de testostérone et d euros Le Paysan de la religion en AllMusic en juillet 1906 p 19-23\n",
      " Articles connexes \n",
      "Bousiers\n",
      "Geotrupinae\n",
      "Anoplotrupes stercorosus\n",
      " Liens externes Ressources relatives aux nazis allemands Elle emploie ce soit en communication 27 novembre 2016 2017 2018 avec le lisant comme les autres personnalités du nucléaire Portail des années plus ancienne productrice afin de quatre textes ont mis\n"
     ]
    }
   ],
   "source": [
    "redacteur = Article_au_hasard(superdico)\n",
    "redacteur.genereruntexte(nb_mot_article)\n",
    "print(redacteur.textealeatoire)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv_generateur': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe3de1a0e7409a2ccc6de6192b3efb31b2ffd52a0bbf7c80c998e5faa22bb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
