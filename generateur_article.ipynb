{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un générérateur d'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autair : Silanoc\n",
    "- octobre 2023\n",
    "- version : 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'un programme qui génére des articles de façon aléatoire. \n",
    "\n",
    "Pour cela, il analyse, dans des textes en entrée, la fréquence des mots qui se suivent.\n",
    "Pour l'entrainer, les textes seront issus de la wikipedia francophone.\n",
    "\n",
    "En sortie un texte aléatoire sera proposé en fonction de ces fréquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoir un corpus de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout manuel\n",
    "\n",
    "On peut mettre en entrée des fichiers .txt directement dans le dossier qui servira de sources plus tard \"vrai_texte\" (par défaut).\n",
    "Le chemin sera à mettre dans la varible \"ou_sont_les_sources\" de la partie \"Enfin, générer notre article\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoir un corpus de texte, extraction de wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code générer avec l'aide de chat-GPT.\n",
    "Il s'agit de sélectionner des articles de la version franophone de wikipedia (par défaut) et d'en extraire le texte sans les mises en forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'articles à extraire\n",
    "# Attention, minimum 2 \n",
    "nombre_articles_a_extraire :int = 2\n",
    "\n",
    "# Où les sauver\n",
    "#chemin_extraction : str =  \"./vrai_texte/wikipedia/\"\n",
    "#chemin_extraction : str =  \"./vrai_texte/hft/\"\n",
    "chemin_extraction : str =  \"./vrai_texte/tout/\"\n",
    "\n",
    "# Choix de la version linguistique \n",
    "langue : str = \"fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le code d'extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_wikipedienne (langue, chemin_extraction, nombre_articles_a_extraire) -> None :\n",
    "    \"\"\"Selectionne au hasard un nombre d'article de wikipédia en chaoissiassant sa langue.\n",
    "    Pour chacun de ces articles, extraire le corps de l'article et le nettoyer de la syntaxe spécifique de wikipédia\n",
    "    Mettre ces textes dans des fichiers txt dont le nom est celui de l'article\n",
    "    \"\"\"\n",
    "    # Définir la langue\n",
    "    wikipedia.set_lang(langue)  \n",
    "\n",
    "    try:\n",
    "        # Obtenir une liste aléatoire de titres d'articles\n",
    "        titles : list[str] = wikipedia.random(nombre_articles_a_extraire)\n",
    "\n",
    "        # Pour chaque article, extraire le contenu et enregistrer dans un fichier\n",
    "        for title in titles:\n",
    "            # Obtenir le contenu de l'article\n",
    "            content = wikipedia.page(title).content\n",
    "\n",
    "            # Supprimer les signes == ou === et double saut de ligne du contenu\n",
    "            content = content.replace(\"===\", \"\")\n",
    "            content = content.replace(\"==\", \"\")\n",
    "            content = content.replace(\"\\n\\n\", \"\")\n",
    "\n",
    "            # Créer un fichier avec le titre de l'article comme nom\n",
    "            file_name = chemin_extraction + title + \".txt\"\n",
    "            with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            print(f\"\"\"Article {title} ajouté\"\"\")\n",
    "    except:\n",
    "        print(f\"\"\"l'article {title} génére une erreur\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Melville Bell Grosvenor ajouté\n",
      "Article WWF (format de fichier) ajouté\n"
     ]
    }
   ],
   "source": [
    "extraction_wikipedienne(langue, chemin_extraction, nombre_articles_a_extraire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction en mode graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lister_les_sous_repertoire(chemin :str = './vrai_texte' )-> list:\n",
    "    \"\"\"Lister tous les sous dossier du dossier ou sont stocké les textes. \n",
    "    Par défaut dans ./vrai texte.\n",
    "    \"\"\"\n",
    "    chemin_repertoire = chemin\n",
    "    sous_repertoires : list = []\n",
    "    # Parcourez le répertoire spécifié\n",
    "    for nom in os.listdir(chemin_repertoire):\n",
    "        chemin = os.path.join(chemin_repertoire, nom)\n",
    "        # Vérifiez si le chemin est un répertoire\n",
    "        if os.path.isdir(chemin):\n",
    "            sous_repertoires.append(chemin + \"/\")\n",
    "    return sous_repertoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gérer les fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se simplifier la vie (ou pas), tout ce qui touche à l'ouverture, lecture, écriture de fichiers est regroupé dans une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestionfichier():\n",
    "    \"\"\"classe pour gérer les dossiers et fichiers\"\"\"\n",
    "    \n",
    "    def lister_fichier(self, source : str)-> list:\n",
    "        \"\"\"pour tous les fichiers du dossier, \n",
    "        on fait confiance qu'il ne s'agit que d'un texte,\n",
    "        mettre tous les noms dans une liste\n",
    "        arg\n",
    "        - source (str) : chemin du dossier\n",
    "        return\n",
    "        - tousleschemins(liste) : liste avec les nom des image dans la source\n",
    "        \"\"\"\n",
    "        tousleschemins: list = []\n",
    "        for fichier in os.listdir(source):\n",
    "            tousleschemins.append(chemin_extraction + fichier)\n",
    "        return tousleschemins\n",
    " \n",
    "    def lirefichier(self, chemin: str)-> str:\n",
    "        \"\"\"ouvre un fichier et transfert son contenue dans une chaine\n",
    "        arg\n",
    "        - chemin (str) : chemin du dossier\n",
    "        return\n",
    "        - contenu_du_fichier (str) : le contenu du fichier\"\"\"\n",
    "        fichier = open(chemin, 'r')\n",
    "        contenu_du_fichier: str = fichier.read()\n",
    "        return contenu_du_fichier\n",
    "    \n",
    "    def ecrirefichier(self, chemin: str, nom: str, contenu: str)-> None:\n",
    "        \"\"\"ecrit un chaine dans un fichier\"\"\"\n",
    "        with open(f\"{chemin}/{nom}.txt\", \"w\", encoding=\"utf-8\") as fichier_sorti:\n",
    "            fichier_sorti.write(contenu)\n",
    "            fichier_sorti.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_source():\n",
    "    \"\"\"chaque article qui servira d'entrée en apprentissage sera mis dans un objet pour analyse, extraction...\"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            une chaine de texte (si possible longue)\n",
    "        return :\n",
    "            aucun\n",
    "        \"\"\"\n",
    "        self.texte:str = text #le texte sur lequel on travail\n",
    "        self.dicostatique:dict = {} #pour la fonction liste_et_compte_mots\n",
    "        self.dicodoublons:dict = {} #pour la fonction cherche_binomes_mots - ce qui est recherché\n",
    "    \n",
    "    def retirer_ponctuation(self, txt_a_nettoyer:str) -> str:\n",
    "        \"\"\" La première version du logiciel est sommaire. \n",
    "        Pour se simplifier la vie, il faut supprimer tous les signe de ponctuations.\n",
    "        arg:\n",
    "            une chaine de texte avec de la ponctuation\n",
    "        return:\n",
    "            une chaine de texte sans ponctuation\n",
    "        \"\"\"\n",
    "        ponctuation : list = [\",\",\";\",\":\",\"!\",\"?\",\".\",\"/\",\"«\",\"»\",'\"',\"–\",\"(\",\")\"]\n",
    "        for signe in ponctuation:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(signe, \"\")\n",
    "        #mettre un espace entre les mots avec apostrophe afin de bien les séparer\n",
    "        apostrophe = [\"’\",\"'\"]\n",
    "        for apost in apostrophe:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(apost, \" \")\n",
    "        #quand on supprime un : par exemple, cela fait deux espace. Remplacer ces artefacts de cagage\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\"  \", \" \")\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\" \", \" \")\n",
    "        return txt_a_nettoyer\n",
    "\n",
    "    def liste_et_compte_mots(self, texte_a_traiter:str) -> list[list,dict]:\n",
    "        \"\"\"Compte le nombre d'occurence d'un mot.\n",
    "        Fonction créée un peu par erreur, mais elle peut être utile pour faire des statistiques.\n",
    "        arg : \n",
    "            texte_a_traiter (str)\n",
    "        return : \n",
    "            2 object dans un liste. La liste des mots de la chaine et le comptrage de chaque mot dans un dictionnaire\n",
    "            \"\"\"\n",
    "        liste_mot: list[str] = texte_a_traiter.split(\" \")\n",
    "        dicostatistique = {}\n",
    "        for mot in liste_mot:\n",
    "            if mot in dicostatistique:\n",
    "                dicostatistique[mot] += 1\n",
    "            else:\n",
    "                dicostatistique[mot] = 1\n",
    "        return [liste_mot, dicostatistique]\n",
    "    \n",
    "    def cherche_binomes_mots(self, texte_a_traiter:str) -> dict:\n",
    "        \"\"\"la fonction principale de l'objet : faire un dictionnaire de fréquences des mots qui se suivent. \n",
    "        arg :\n",
    "            self\n",
    "        return :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "        \"\"\"\n",
    "        liste_mots_suivant:list = []\n",
    "        dicodoublons:dict = {}\n",
    "        #recherche des espaces délimitants les mots\n",
    "        list_position_espace = []\n",
    "        for i in range(len(texte_a_traiter)):\n",
    "            if texte_a_traiter[i] == \" \":\n",
    "                list_position_espace.append(i)\n",
    "        #print(list_position_espace)\n",
    "        #recherche doublons mot\n",
    "        debut1 = 0\n",
    "        for i in range(len(list_position_espace)-2): #AFAIRE : ATTENTION ça ne prends pas les deux derniers mot. A vérifier.\n",
    "            fin1 = list_position_espace[i]\n",
    "            fin2 = list_position_espace[i + 1]\n",
    "            #print(debut1, fin1,fin2)\n",
    "            mot1 = texte_a_traiter[debut1:fin1]\n",
    "            mot2 = texte_a_traiter[fin1:fin2]\n",
    "            debut1 = list_position_espace[i]\n",
    "            #print(mot1,mot2)\n",
    "            liste_mots_suivant.append([mot1, mot2])\n",
    "        #print(liste_mots_suivant)\n",
    "        #fait un dictionnaire avec toutes les occurences possible après un même mot.\n",
    "        #les doublons sont normaux, cela veut dire que le mot revient plusieurs fois, cela correspond au calcul de leur fréquence   \n",
    "        for j in range(len(liste_mots_suivant)):\n",
    "            if liste_mots_suivant[j][0] in dicodoublons.keys():\n",
    "                #print('doublons')\n",
    "                dicodoublons[liste_mots_suivant[j][0]].append(liste_mots_suivant[j][1])\n",
    "            else:\n",
    "                #print('nouveau')\n",
    "                dicodoublons[liste_mots_suivant[j][0]]=[(liste_mots_suivant[j][1])]\n",
    "        # Warning : il y a des espace en trop (tenu en compte pour le reste et tests)\n",
    "        return dicodoublons \n",
    "    \n",
    "    def tout_enchainer(self) -> dict :\n",
    "        self.texte = self.retirer_ponctuation(self.texte)\n",
    "        #self.dicostatique = self.liste_et_compte_mots(self.texte)[1]\n",
    "        #print(self.dicostatique)\n",
    "        #print(\"--------------\")\n",
    "        dicodoublons_txt = self.cherche_binomes_mots(self.texte)\n",
    "        return dicodoublons_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_au_hasard():\n",
    "    \"\"\"génére un texte aléatoire à partir d'un dictionnaire\n",
    "    \n",
    "        arg :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "            typiquement le dictionnaire généré par le return de cherche_binomes_mots(), ou d'une sauvegarde issus de cette fonction.\n",
    "        \n",
    "        return\n",
    "            une chaine de texte avec les mots du dictionnaire dans un ordre aléatoire.\n",
    "            elle pourra aller dans un doc txt pour sauvegarde\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mondico:dict):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            mondico (dict) : pour chaque mot en cle dedans, il y a une liste de mot possible.\n",
    "        \"\"\"\n",
    "        self.mondico: dict = mondico #le dictionnaire sur lequel on travail\n",
    "        self.textealeatoire : str =\"\" #le texte que l'on veut\n",
    "    \n",
    "    def choixmotpourcommencer(self, dico: dict)-> str:\n",
    "        \"\"\"a utiliser pour le premier mot, \n",
    "        mais aussi si un mot ne peut pas en trouver d'autre, faire une proposition pour eviter une erreur et continuer\n",
    "        \"\"\"\n",
    "        #Mettre les clefs dans une liste\n",
    "        liste_des_mots : list = []\n",
    "        for key in dico:\n",
    "            liste_des_mots.append(key)\n",
    "        #choix lui meme\n",
    "        mot: str = liste_des_mots[random.randint(0, len(liste_des_mots))]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "\n",
    "    def chercherlemotsuivant(self, dico: dict, mot: str) -> str:\n",
    "        \"\"\"à partir d'un mot, sortir aléatoire un mot dans ceux pouvant le suivre stocké dans le dictionnaire\"\"\"\n",
    "        liste_des_possible: list = dico[\" \" + mot] #WARNING on remet un espace car dans la version du moment, il y a un espace dans le dico et c'est pas bien\n",
    "        mot: str = liste_des_possible[random.randint(0, len(liste_des_possible) -1 )]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "    \n",
    "    def genereruntexte(self, taille_article: int) -> None:\n",
    "        \"\"\"intier avec choixmotpourcommencer(), puis enchainer chercherlemotsuivant()\n",
    "        taille_article est le nombre de mot que l'on veut pour l'article aléatoire\n",
    "        \"\"\"\n",
    "        mot: str = self.choixmotpourcommencer(self.mondico)\n",
    "        self.textealeatoire += mot\n",
    "        for _ in range(taille_article - 1):\n",
    "            new_mot: str = self.chercherlemotsuivant(self.mondico, mot)\n",
    "            mot = new_mot\n",
    "            self.textealeatoire = self.textealeatoire + \" \" + mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additioner des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_dico(grand_dico : dict, petit_dico : dict)-> dict:\n",
    "    \"\"\"Permet de mettre le contenu d'un dictionnaire dans un autre.\n",
    "    Si dans les deux dic, il y a une clef commune, il concatène les deux listes de mot\n",
    "    \"\"\"\n",
    "    for keys, values in petit_dico.items():\n",
    "        if keys in grand_dico:\n",
    "            liste_intermediaire = grand_dico[keys]\n",
    "            for item in values:\n",
    "                liste_intermediaire.append(item)\n",
    "            grand_dico[keys] = liste_intermediaire\n",
    "        else:\n",
    "            grand_dico[keys] = values\n",
    "    return grand_dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser tous les fichiers d'un dossier et en faire un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_dossier_et_faire_dico(source : str) -> dict:\n",
    "    \"\"\"Pour tous les fichiers d'un dossier, \n",
    "    lire le contenue, en faire le dictionnaire \n",
    "    et fusionner tous les dictionnaire en un seul.\n",
    "    arg:\n",
    "    - source (str) : chemin d'un dossier\n",
    "    return:\n",
    "    - dict_statistique (dict)\n",
    "    \"\"\"\n",
    "    gestionnaire = Gestionfichier()\n",
    "    lesfichichiers = gestionnaire.lister_fichier(source)\n",
    "    #print(lesfichichiers)\n",
    "    dict_statistique = {}\n",
    "    for item in lesfichichiers:\n",
    "        contenu_a_analyser = gestionnaire.lirefichier(item)\n",
    "        analyseur = Article_source(contenu_a_analyser)\n",
    "        dico_item = analyseur.tout_enchainer()\n",
    "        dict_statistique = addition_dico(dict_statistique, dico_item)\n",
    "    return dict_statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfin, générer notre article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des fichiers de 'vrai_texte/wikipedia', génére un texte de 250 mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou_sont_les_sources = \"vrai_texte/wikipedia\"\n",
    "#ou_sont_les_sources = \"vrai_texte/hft\"\n",
    "ou_sont_les_sources : str = \"vrai_texte/tout\"\n",
    "nb_mot_article : int = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer le dictionnaire qui pourra être réutilisé plusieurs fois\n",
    "superdico = analyser_dossier_et_faire_dico(ou_sont_les_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(superdico, nb_mot_article) -> None :\n",
    "    redacteur = Article_au_hasard(superdico)\n",
    "    redacteur.genereruntexte(nb_mot_article)\n",
    "    article_aleatoire_redige = redacteur.textealeatoire\n",
    "    return article_aleatoire_redige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saitō\n",
      "Montage Akira Kurosawa\n",
      "Musique Masaru Satō\n",
      "Décors Yoshirō Muraki\n",
      "Costumes Miyuki Suzuki\n",
      "Sociétés de la Découverte\n",
      "Commande d orgue Mascioni opus 205 est illicite article est tirée il reviendra en service est juste la police je crache mon singe\n",
      "enfin seuls\n",
      "\n",
      "jardins métalloïdes\n",
      "noyés de Burislav dans winnie l air\n",
      "du côté pair & glacés\n",
      "de tes mutants\n",
      "sur la somme avoisinant les illustrations du Dharma pratiquant en Mallorca Del Rio premier vainqueur de la France sur les deux siècles mais laisse pas de porc qui refleurit\n",
      "fait transpirer le duc de Limani Amchidé une épave au bout des droits sont amusés à choisir d identité\n",
      "ganja \n",
      "\n",
      "ma tête entre des membres abandonnèrent l inventeur garde des droits exclusifs accordés au printemps 1782 laissant la Lituanie Portail de l instruction maître particulier de la médaille de ce matin banal\n",
      "d un dieu\n",
      "Fétide prisonnier d analyse reste étant inconnues sont rattachées à une équipe du 10 avril 2001 et de tes féeries solitaires\n",
      "\n",
      "& tu vois devant un univers je jetterai mes voyelles\n",
      "Auprès de ce taxon Halielloides Bouchet & déméter les lignes à Bagdad et se soigner des immutables et non arrêtez arrêtez arrêtez ah ah oui je fabrique\n",
      "des chansons voulaient dire\n",
      "agenouillée dans les vivants\n",
      "\n",
      "à force brutale aveugle le fleuve Bleu mais prend la reine noire *bis*\n",
      "\n",
      "tes amants de rap à travers les latrines\n",
      "la nuit au milieu de Paradis Gloutier Ch Magallon Beauchamp avocat en noir qui s DragCon LA et des industriels composés de l interprétation plus à la saison 1987 à l arbre mort\n",
      "au milieu du racket\n",
      "m ont compris que des femmes et de\n"
     ]
    }
   ],
   "source": [
    "# Cellule à exécuter pour un nouveau texte\n",
    "article_obtenue = generation(superdico, nb_mot_article)\n",
    "print(article_obtenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour horodater le fichier\n",
    "def horodatage():\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d%H%M%S%f\") #A la micro-seconde prêt \n",
    "    return timestamp\n",
    "    # print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoir_un_fichier(article_a_ecrire = article_obtenue)-> None:\n",
    "    \"\"\"écrire l'article voulu dans une fichier texte, en l'horodatant\"\"\"\n",
    "    ecrivain = Gestionfichier()\n",
    "    ecrivain.ecrirefichier(\"./textes_generes\", str(horodatage()), article_a_ecrire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoir_un_fichier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe3de1a0e7409a2ccc6de6192b3efb31b2ffd52a0bbf7c80c998e5faa22bb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
