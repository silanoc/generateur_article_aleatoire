{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un générérateur d'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autair : Silanoc\n",
    "- avril 2022\n",
    "- version : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'avoir un programme qui génére des articles de façon aléatoire. Pour cela, il analyse dans des textes la fréquence des mots qui se suivent.\n",
    "Pour l'entrainer, les textes seront issus de wikipedia francophone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoir un corpus de texte, extraction de wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code générer avec l'aide de chat-GPT.\n",
    "Il s'agit de sélectionner des articles de la version franophone de wikipedia (par défaut) et d'en extraire le texte sans les mises en forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'articles à extraire\n",
    "# Attention, minimum 2 \n",
    "nombre_articles_a_extraire = 2\n",
    "\n",
    "# Où les sauver\n",
    "#chemin_extraction =  \"./vrai_texte/wikipedia/\"\n",
    "#chemin_extraction =  \"./vrai_texte/hft/\"\n",
    "chemin_extraction =  \"./vrai_texte/tout/\"\n",
    "\n",
    "\n",
    "# Choix de la version linguistique \n",
    "langue = \"fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba4b473bd4b4c718f139bf788f6e12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=3, description=\"Combien d'articles voulez vous extraire ?\", layout=Layout(height='50px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "choix_nb_article = widgets.BoundedIntText(\n",
    "    value = 3,min = 2,max = 20, step = 1,\n",
    "    description=\"Combien d'articles voulez vous extraire ?\", style=style, \n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    width='25%', height='160px',\n",
    "    layout=widgets.Layout(width='100%', height='50px'))\n",
    "display(choix_nb_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombre_articles_a_extraire = choix_nb_article.value\n",
    "nombre_articles_a_extraire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le code d'extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Takechi no Kurohito ajouté\n",
      "Article Pierre Joseph de Beauchamp ajouté\n",
      "Article Velehrad ajouté\n",
      "Article Stad Doetinchem ajouté\n",
      "Article Laganja Estranja ajouté\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "# Définir la langue\n",
    "wikipedia.set_lang(langue)  \n",
    "\n",
    "try:\n",
    "    # Obtenir une liste aléatoire de titres d'articles\n",
    "    titles = wikipedia.random(nombre_articles_a_extraire)\n",
    "\n",
    "    # Pour chaque article, extraire le contenu et enregistrer dans un fichier\n",
    "    for title in titles:\n",
    "        # Obtenir le contenu de l'article\n",
    "        content = wikipedia.page(title).content\n",
    "        \n",
    "        # Supprimer les signes == ou === et double saut de ligne du contenu\n",
    "        content = content.replace(\"===\", \"\")\n",
    "        content = content.replace(\"==\", \"\")\n",
    "        content = content.replace(\"\\n\\n\", \"\")\n",
    "            \n",
    "        # Créer un fichier avec le titre de l'article comme nom\n",
    "        file_name = chemin_extraction + title + \".txt\"\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        print(f\"\"\"Article {title} ajouté\"\"\")\n",
    "except:\n",
    "    print(f\"\"\"l'article {title} génére une erreur\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gérer les fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se simplifier la vie (ou pas), tout ce qui touche à l'ouverture, lecture, écriture de fichiers est regroupé dans une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestionfichier():\n",
    "    \"\"\"classe pour gérer les dossiers et fichiers\"\"\"\n",
    "    \n",
    "    def lister_fichier(self, source : str)-> list:\n",
    "        \"\"\"pour tous les fichiers du dossier, \n",
    "        on fait confiance qu'il ne s'agit que d'un texte,\n",
    "        mettre tous les noms dans une liste\n",
    "        arg\n",
    "        - source (str) : chemin du dossier\n",
    "        return\n",
    "        - tousleschemins(liste) : liste avec les nom des image dans la source\n",
    "        \"\"\"\n",
    "        tousleschemins: list = []\n",
    "        for fichier in os.listdir(source):\n",
    "            tousleschemins.append(chemin_extraction + fichier)\n",
    "        return tousleschemins\n",
    "\n",
    " \n",
    "    def lirefichier(self, chemin: str)-> str:\n",
    "        \"\"\"ouvre un fichier et transfert son contenue dans une chaine\n",
    "        arg\n",
    "        - chemin (str) : chemin du dossier\n",
    "        return\n",
    "        - contenu_du_fichier (str) : le contenu du fichier\"\"\"\n",
    "        fichier = open(chemin, 'r')\n",
    "        contenu_du_fichier: str = fichier.read()\n",
    "        return contenu_du_fichier\n",
    "    \n",
    "    \n",
    "    def ecrirefichier(self, chemin: str, nom: str, contenu: str)->None:\n",
    "        \"\"\"ecrit un chaine dans un fichier\"\"\"\n",
    "        with open(f\"{chemin}/{nom}.txt\", \"w\", encoding=\"utf-8\") as fichier_sorti:\n",
    "            fichier_sorti.write(contenu)\n",
    "            fichier_sorti.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_source():\n",
    "    \"\"\"chaque article qui servira d'entrée en apprentissage sera mis dans un objet pour analyse, extraction...\"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            une chaine de texte (si possible longue)\n",
    "        return :\n",
    "            aucun\n",
    "        \"\"\"\n",
    "        self.texte:str = text #le texte sur lequel on travail\n",
    "        self.dicostatique:dict = {} #pour la fonction liste_et_compte_mots\n",
    "        self.dicodoublons:dict = {} #pour la fonction cherche_binomes_mots - ce qui est recherché\n",
    "    \n",
    "    def retirer_ponctuation(self, txt_a_nettoyer:str) -> str:\n",
    "        \"\"\" La première version du logiciel est sommaire. \n",
    "        Pour se simplifier la vie, il faut supprimer tous les signe de ponctuations.\n",
    "        arg:\n",
    "            une chaine de texte avec de la ponctuation\n",
    "        return:\n",
    "            une chaine de texte sans ponctuation\n",
    "        \"\"\"\n",
    "        ponctuation : list = [\",\",\";\",\":\",\"!\",\"?\",\".\",\"/\",\"«\",\"»\",'\"',\"–\",\"(\",\")\"]\n",
    "        for signe in ponctuation:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(signe, \"\")\n",
    "        #mettre un espace entre les mots avec apostrophe afin de bien les séparer\n",
    "        apostrophe = [\"’\",\"'\"]\n",
    "        for apost in apostrophe:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(apost, \" \")\n",
    "        #quand on supprime un : par exemple, cela fait deux espace. Remplacer ces artefacts de cagage\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\"  \", \" \")\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\" \", \" \")\n",
    "        return txt_a_nettoyer\n",
    "\n",
    "    def liste_et_compte_mots(self, texte_a_traiter:str) -> list[list,dict]:\n",
    "        \"\"\"Compte le nombre d'occurence d'un mot.\n",
    "        Fonction créée un peu par erreur, mais elle peut être utile pour faire des statistiques.\n",
    "        arg : \n",
    "            texte_a_traiter (str)\n",
    "        return : \n",
    "            2 object dans un liste. La liste des mots de la chaine et le comptrage de chaque mot dans un dictionnaire\n",
    "            \"\"\"\n",
    "        liste_mot: list[str] = texte_a_traiter.split(\" \")\n",
    "        dicostatistique = {}\n",
    "        for mot in liste_mot:\n",
    "            if mot in dicostatistique:\n",
    "                dicostatistique[mot] += 1\n",
    "            else:\n",
    "                dicostatistique[mot] = 1\n",
    "        return [liste_mot, dicostatistique]\n",
    "    \n",
    "    def cherche_binomes_mots(self, texte_a_traiter:str) -> dict:\n",
    "        \"\"\"la fonction principale de l'objet : faire un dictionnaire de fréquences des mots qui se suivent. \n",
    "        arg :\n",
    "            self\n",
    "        return :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "        \"\"\"\n",
    "        liste_mots_suivant:list = []\n",
    "        dicodoublons:dict = {}\n",
    "        #recherche des espaces délimitants les mots\n",
    "        list_position_espace = []\n",
    "        for i in range(len(texte_a_traiter)):\n",
    "            if texte_a_traiter[i] == \" \":\n",
    "                list_position_espace.append(i)\n",
    "        #print(list_position_espace)\n",
    "        #recherche doublons mot\n",
    "        debut1 = 0\n",
    "        for i in range(len(list_position_espace)-2): #AFAIRE : ATTENTION ça ne prends pas les deux derniers mot. A vérifier.\n",
    "            fin1 = list_position_espace[i]\n",
    "            fin2 = list_position_espace[i + 1]\n",
    "            #print(debut1, fin1,fin2)\n",
    "            mot1 = texte_a_traiter[debut1:fin1]\n",
    "            mot2 = texte_a_traiter[fin1:fin2]\n",
    "            debut1 = list_position_espace[i]\n",
    "            #print(mot1,mot2)\n",
    "            liste_mots_suivant.append([mot1, mot2])\n",
    "        #print(liste_mots_suivant)\n",
    "        #fait un dictionnaire avec toutes les occurences possible après un même mot.\n",
    "        #les doublons sont normaux, cela veut dire que le mot revient plusieurs fois, cela correspond au calcul de leur fréquence   \n",
    "        for j in range(len(liste_mots_suivant)):\n",
    "            if liste_mots_suivant[j][0] in dicodoublons.keys():\n",
    "                #print('doublons')\n",
    "                dicodoublons[liste_mots_suivant[j][0]].append(liste_mots_suivant[j][1])\n",
    "            else:\n",
    "                #print('nouveau')\n",
    "                dicodoublons[liste_mots_suivant[j][0]]=[(liste_mots_suivant[j][1])]\n",
    "        # Warning : il y a des espace en trop (tenu en compte pour le reste et tests)\n",
    "        return dicodoublons \n",
    "    \n",
    "    def tout_enchainer(self) -> dict :\n",
    "        self.texte = self.retirer_ponctuation(self.texte)\n",
    "        #self.dicostatique = self.liste_et_compte_mots(self.texte)[1]\n",
    "        #print(self.dicostatique)\n",
    "        #print(\"--------------\")\n",
    "        dicodoublons_txt = self.cherche_binomes_mots(self.texte)\n",
    "        return dicodoublons_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester les méthodes de la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import Mock, patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_analyse():\n",
    "    \n",
    "    def test_retirer_ponctuation(self):\n",
    "        chaine = \"Le, petit chat d'Hercule est mort !\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        retirer = textdebase.retirer_ponctuation(chaine)\n",
    "        assert retirer == \"Le petit chat d Hercule est mort \"\n",
    "        \n",
    "    def test_liste_et_compte_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        list_mot = textdebase.liste_et_compte_mots(chaine)[0]\n",
    "        dico_mot = textdebase.liste_et_compte_mots(chaine)[1]\n",
    "        assert list_mot == ['le','petit','chat','de','béatrice','est','sur','le','petit','mur','du','jardin','de','Yves']\n",
    "        assert dico_mot == {'le':2,'petit':2,'chat':1,'de':2,'béatrice':1,'est':1,'sur':1,'mur':1,'du':1,'jardin':1,'Yves':1}\n",
    "     \n",
    "    \"\"\"  \n",
    "    #code pour tester une erreur dans jupyter \n",
    "    def test_cherche_binomes_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        dico = textdebase.cherche_binomes_mots(chaine)\n",
    "        assert dico == {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeur = Test_modele_analyse()\n",
    "testeur.test_retirer_ponctuation()\n",
    "testeur.test_liste_et_compte_mots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_au_hasard():\n",
    "    \"\"\"génére un texte aléatoire à partir d'un dictionnaire\n",
    "    \n",
    "        arg :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "            typiquement le dictionnaire généré par le return de cherche_binomes_mots(), ou d'une sauvegarde issus de cette fonction.\n",
    "        \n",
    "        return\n",
    "            une chaine de texte avec les mots du dictionnaire dans un ordre aléatoire.\n",
    "            elle pourra aller dans un doc txt pour sauvegarde\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mondico:dict):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            mondico (dict) : pour chaque mot en cle dedans, il y a une liste de mot possible.\n",
    "        \"\"\"\n",
    "        self.mondico: dict = mondico #le dictionnaire sur lequel on travail\n",
    "        self.textealeatoire : str =\"\" #le texte que l'on veut\n",
    "    \n",
    "    def choixmotpourcommencer(self, dico: dict)-> str:\n",
    "        \"\"\"a utiliser pour le premier mot, \n",
    "        mais aussi si un mot ne peut pas en trouver d'autre, faire une proposition pour eviter une erreur et continuer\n",
    "        \"\"\"\n",
    "        #Mettre les clefs dans une liste\n",
    "        liste_des_mots : list = []\n",
    "        for key in dico:\n",
    "            liste_des_mots.append(key)\n",
    "        #choix lui meme\n",
    "        mot: str = liste_des_mots[random.randint(0, len(liste_des_mots))]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "\n",
    "    def chercherlemotsuivant(self, dico: dict, mot: str) -> str:\n",
    "        \"\"\"à partir d'un mot, sortir aléatoire un mot dans ceux pouvant le suivre stocké dans le dictionnaire\"\"\"\n",
    "        liste_des_possible: list = dico[\" \" + mot] #WARNING on remet un espace car dans la version du moment, il y a un espace dans le dico et c'est pas bien\n",
    "        mot: str = liste_des_possible[random.randint(0, len(liste_des_possible) -1 )]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "    \n",
    "    def genereruntexte(self, taille_article: int) -> None:\n",
    "        \"\"\"intier avec choixmotpourcommencer(), puis enchainer chercherlemotsuivant()\n",
    "        taille_article est le nombre de mot que l'on veut pour l'article aléatoire\n",
    "        \"\"\"\n",
    "        mot: str = self.choixmotpourcommencer(self.mondico)\n",
    "        self.textealeatoire += mot\n",
    "        for _ in range(taille_article - 1):\n",
    "            new_mot: str = self.chercherlemotsuivant(self.mondico, mot)\n",
    "            mot = new_mot\n",
    "            self.textealeatoire = self.textealeatoire + \" \" + mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester la class Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_generation():\n",
    "    \n",
    "    def test_choixmotpourcommencer(self, mocker):\n",
    "        dictionnaire = {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "        mocker.patch('random.randint', return_value=1)\n",
    "        generation = Article_au_hasard(dictionnaire)\n",
    "        generation.mot = generation.choixmotpourcommencer(dictionnaire)\n",
    "        assert generation.mot == \"petit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'patch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m testeur_article \u001b[38;5;241m=\u001b[39m Test_modele_generation()\n\u001b[0;32m----> 2\u001b[0m testeur_article\u001b[38;5;241m.\u001b[39mtest_choixmotpourcommencer(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mTest_modele_generation.test_choixmotpourcommencer\u001b[0;34m(self, mocker)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_choixmotpourcommencer\u001b[39m(\u001b[38;5;28mself\u001b[39m, mocker):\n\u001b[1;32m      4\u001b[0m     dictionnaire \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m----> 6\u001b[0m     mocker\u001b[38;5;241m.\u001b[39mpatch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom.randint\u001b[39m\u001b[38;5;124m'\u001b[39m, return_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     generation \u001b[38;5;241m=\u001b[39m Article_au_hasard(dictionnaire)\n\u001b[1;32m      8\u001b[0m     generation\u001b[38;5;241m.\u001b[39mmot \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mchoixmotpourcommencer(dictionnaire)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'patch'"
     ]
    }
   ],
   "source": [
    "testeur_article = Test_modele_generation()\n",
    "testeur_article.test_choixmotpourcommencer(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additioner des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_dico(grand_dico : dict, petit_dico : dict)-> dict:\n",
    "    \"\"\"Permet de mettre le contenu d'un dictionnaire dans un autre.\n",
    "    Si dans les deux dic, il y a une clef commune, il concatène les deux listes de mot\"\"\"\n",
    "    for keys, values in petit_dico.items():\n",
    "        if keys in grand_dico:\n",
    "            liste_intermediaire = grand_dico[keys]\n",
    "            for item in values:\n",
    "                liste_intermediaire.append(item)\n",
    "            grand_dico[keys] = liste_intermediaire\n",
    "        else:\n",
    "            grand_dico[keys] = values\n",
    "    return grand_dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tester l'addition de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_addition_dico():\n",
    "    dico1 = {'a' : ['le', 'petit'], 'b' : ['chat', 'de']}\n",
    "    dico2 = {'b' : ['de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    dico3 = addition_dico(dico1, dico2)\n",
    "    assert dico3 == {'a' : ['le', 'petit'], 'b' : ['chat', 'de', 'de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    \n",
    "test_addition_dico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser tous les fichiers d'un dossier et en faire un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_dossier_et_faire_dico(source : str) -> dict:\n",
    "    \"\"\"Pour tous les fichiers d'un dossier, \n",
    "    lire le contenue, en faire le dictionnaire \n",
    "    et fusionner tous les dictionnaire en un seul.\n",
    "    arg:\n",
    "    - source (str) : chemin d'un dossier\n",
    "    return:\n",
    "    - dict_statistique (dict)\n",
    "    \"\"\"\n",
    "    gestionnaire =Gestionfichier()\n",
    "    lesfichichiers = gestionnaire.lister_fichier(source)\n",
    "    #print(lesfichichiers)\n",
    "    dict_statistique = {}\n",
    "    for item in lesfichichiers:\n",
    "        contenu_a_analyser = gestionnaire.lirefichier(item)\n",
    "        analyseur = Article_source(contenu_a_analyser)\n",
    "        dico_item = analyseur.tout_enchainer()\n",
    "        dict_statistique = addition_dico(dict_statistique, dico_item)\n",
    "    return dict_statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfin, générer notre article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des fichiers de 'vrai_texte/wikipedia', génére un texte de 250 mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou_sont_les_sources = \"vrai_texte/wikipedia\"\n",
    "#ou_sont_les_sources = \"vrai_texte/hft\"\n",
    "ou_sont_les_sources = \"vrai_texte/tout\"\n",
    "nb_mot_article = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer le dictionnaire qui pourra être réutilisé plusieurs fois\n",
    "superdico = analyser_dossier_et_faire_dico(ou_sont_les_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation():\n",
    "    redacteur = Article_au_hasard(superdico)\n",
    "    redacteur.genereruntexte(nb_mot_article)\n",
    "    article_aleatoire_redige = redacteur.textealeatoire\n",
    "    return article_aleatoire_redige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stériles d eau douce comme un risque sur toute la Banque de matinée L action au pied de domestique en soi mais une partie nord-ouest du feu Cette technique de Voynich Studies sur ton jour si mal\n",
      "ta vie & tremblant\n",
      "dans l empereur Cependant toute forme de tels que des performances face nord\n",
      "\n",
      "je m rappelles mes lubies sentimentales\n",
      "\n",
      "lorsque son doberman\n",
      "c est souvent critiqué ce dernier topless-bar\n",
      "terrien terrien\n",
      "terrien t en 2005 \n",
      " Description \n",
      " Saison régulière ou elle suit au 17 articles et blanc\n",
      " L agriculture — Mânavadharmashâstra livre 10 mai 1820 à Paris Éditions Rythme et si ça continue par comté\n",
      "Iowa\n",
      " Source \n",
      "Bibliothèque nationale des sanctions pour couronner son trou\n",
      "& vient pas nécessaire Cette sculpture et aux yeux de leurs initiales gravées sur le dessous de vagues d un amour ou données pouvant pas porter atteinte aux infractions constatées STIC Le compositeur a permis pour me demande si tu pleures en le froid froid de recyclage\n",
      "des mélancolies hors Mayotte +19 %\n",
      "= Pyramide des idées\n",
      "Ce cadre du tennis d œuvres de classement auprès du ROTC corps de la Manche entre l État pour me visse à la lumière vagabonde\n",
      "filait à un coup du mauvais don à octobre 1983[2]\n",
      "Il démissionna de Christian V Cette révélation du Premier ministre de meurtre ou modèles dans les grumes aux beaux-arts Musée de commémorer par Philippe Odoul ISBN 978-84-88306-26-5\n",
      "es La Tentation sarrasine de William Wyler par Darius Milhaud Honegger et leur corps vivant a produit ou moins zéro\n",
      "\n",
      "& puis Heathcliff est préférable de Wikipédia doit déposer le\n"
     ]
    }
   ],
   "source": [
    "# Cellule à exécuter pour un nouveau texte\n",
    "article_obtenue = generation()\n",
    "print(article_obtenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour horodater le fichier\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def horodatage():\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    return timestamp\n",
    "    # print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoir_un_fichier():\n",
    "    ecrivain = Gestionfichier()\n",
    "    ecrivain.ecrirefichier(\"./textes_generes\", str(horodatage()), article_obtenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoir_un_fichier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe3de1a0e7409a2ccc6de6192b3efb31b2ffd52a0bbf7c80c998e5faa22bb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
