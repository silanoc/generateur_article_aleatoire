{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un générérateur d'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'avoir un programme qui génére des articles de façon aléatoire. Pour cela, il analyse dans des textes la fréquences des mots qui se suivent.\n",
    "Pour l'entrainer, les textes seront issus de wikipedia francophone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoir un corpus de texte, extraction de wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer avec l'aide de chat-GPT.\n",
    "Il s'agit de sélectionner des article de la wikipedia française (par défaut) et d'en prendre le texte sans les mises en forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'articles à extraire\n",
    "# Attention, minimum 2 \n",
    "nombre_articles_a_extraire = 2\n",
    "\n",
    "# Où les sauver\n",
    "chemin_extraction =  \"./vrai_texte/wikipedia/\"\n",
    "\n",
    "# Choix de la version linguistique \n",
    "langue = \"fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le code d'extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Pentamètre iambique ajouté\n",
      "Article Gare de l'Université Hadj Lakhdar ajouté\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "\n",
    "# Définir la langue\n",
    "wikipedia.set_lang(langue)  \n",
    "\n",
    "try:\n",
    "    # Obtenir une liste aléatoire de titres d'articles\n",
    "    titles = wikipedia.random(nombre_articles_a_extraire)\n",
    "\n",
    "    # Pour chaque article, extraire le contenu et enregistrer dans un fichier\n",
    "    for title in titles:\n",
    "        # Obtenir le contenu de l'article\n",
    "        content = wikipedia.page(title).content\n",
    "        \n",
    "        # Supprimer les signes == ou === et double saut de ligne du contenu\n",
    "        content = content.replace(\"===\", \"\")\n",
    "        content = content.replace(\"==\", \"\")\n",
    "        content = content.replace(\"\\n\\n\", \"\")\n",
    "            \n",
    "        # Créer un fichier avec le titre de l'article comme nom\n",
    "        file_name = chemin_extraction + title + \".txt\"\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        print(f\"\"\"Article {title} ajouté\"\"\")\n",
    "except:\n",
    "    print(f\"\"\"l'article {title} génére une erreur\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv_generateur': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe3de1a0e7409a2ccc6de6192b3efb31b2ffd52a0bbf7c80c998e5faa22bb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
