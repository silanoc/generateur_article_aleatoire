{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un générérateur d'article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autair : Silanoc\n",
    "- octobre 2023\n",
    "- version : 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'un programme qui génére des articles de façon aléatoire. \n",
    "\n",
    "Pour cela, il analyse, dans des textes en entrée, la fréquence des mots qui se suivent.\n",
    "Pour l'entrainer, les textes seront issus de la wikipedia francophone.\n",
    "\n",
    "En sortie un texte aléatoire sera proposé en fonction de ces fréquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "import wikipedia\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoir un corpus de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ajout manuel\n",
    "\n",
    "On peut mettre en entrée des fichiers .txt directement dans le dossier qui servira de sources plus tard \"vrai_texte\" (par défaut).\n",
    "Le chemin sera à mettre dans la varible \"ou_sont_les_sources\" de la partie \"Enfin, générer notre article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='img_et_titre' style=\"display: flex ; flex-direction:row\">\n",
       "    <img src=\"./statics/wikipedia.png\"/> \n",
       "    <h3 style=\"color:ff0\">Avoir un corpus de texte, extraction de wikipedia.</h3>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div class='img_et_titre' style=\"display: flex ; flex-direction:row\">\n",
    "    <img src=\"./statics/wikipedia.png\"/> \n",
    "    <h3 style=\"color:ff0\">Avoir un corpus de texte, extraction de wikipedia.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code générer avec l'aide de chat-GPT.\n",
    "Il s'agit de sélectionner des articles de la version franophone de wikipedia (par défaut) et d'en extraire le texte sans les mises en forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le nombre d'articles à extraire\n",
    "# Attention, minimum 2 \n",
    "nombre_articles_a_extraire :int = 2\n",
    "\n",
    "# Où les sauver\n",
    "#chemin_extraction : str =  \"./vrai_texte/wikipedia/\"\n",
    "#chemin_extraction : str =  \"./vrai_texte/hft/\"\n",
    "chemin_extraction : str =  \"./vrai_texte/tout/\"\n",
    "\n",
    "# Choix de la version linguistique \n",
    "langue : str = \"fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a294581ad340469b6d690360480265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=3, description=\"Combien d'articles voulez vous extraire ?\", layout=Layout(height='50px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "choix_nb_article = widgets.BoundedIntText(\n",
    "    value = 3, min = 2,max = 20, step = 1,\n",
    "    description = \"Combien d'articles voulez vous extraire ?\", style = style, \n",
    "    disabled = False,\n",
    "    continuous_update = False,\n",
    "    readout = True,\n",
    "    width = '25%', height = '160px',\n",
    "    layout = widgets.Layout(width = '100%', height = '50px'))\n",
    "\n",
    "display(choix_nb_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombre_articles_a_extraire = choix_nb_article.value\n",
    "nombre_articles_a_extraire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le code d'extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_wikipedienne (langue, chemin_extraction, nombre_articles_a_extraire) -> None :\n",
    "    \"\"\"Selectionne au hasard un nombre d'article de wikipédia en chaoissiassant sa langue.\n",
    "    Pour chacun de ces articles, extraire le corps de l'article et le nettoyer de la syntaxe spécifique de wikipédia\n",
    "    Mettre ces textes dans des fichiers txt dont le nom est celui de l'article\n",
    "    \"\"\"\n",
    "    # Définir la langue\n",
    "    wikipedia.set_lang(langue)  \n",
    "\n",
    "    try:\n",
    "        # Obtenir une liste aléatoire de titres d'articles\n",
    "        titles : list[str] = wikipedia.random(nombre_articles_a_extraire)\n",
    "\n",
    "        # Pour chaque article, extraire le contenu et enregistrer dans un fichier\n",
    "        for title in titles:\n",
    "            # Obtenir le contenu de l'article\n",
    "            content = wikipedia.page(title).content\n",
    "\n",
    "            # Supprimer les signes == ou === et double saut de ligne du contenu\n",
    "            content = content.replace(\"===\", \"\")\n",
    "            content = content.replace(\"==\", \"\")\n",
    "            content = content.replace(\"\\n\\n\", \"\")\n",
    "\n",
    "            # Créer un fichier avec le titre de l'article comme nom\n",
    "            file_name = chemin_extraction + title + \".txt\"\n",
    "            with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            print(f\"\"\"Article {title} ajouté\"\"\")\n",
    "    except:\n",
    "        print(f\"\"\"l'article {title} génére une erreur\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction en elle même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Campyloptère des Santa Marta ajouté\n",
      "Article Cour suprême de Gambie ajouté\n"
     ]
    }
   ],
   "source": [
    "extraction_wikipedienne(langue, chemin_extraction, nombre_articles_a_extraire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gérer les fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se simplifier la vie (ou pas), tout ce qui touche à l'ouverture, lecture, écriture de fichiers est regroupé dans une classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gestionfichier():\n",
    "    \"\"\"classe pour gérer les dossiers et fichiers\"\"\"\n",
    "    \n",
    "    def lister_fichier(self, source : str)-> list:\n",
    "        \"\"\"pour tous les fichiers du dossier, \n",
    "        on fait confiance qu'il ne s'agit que d'un texte,\n",
    "        mettre tous les noms dans une liste\n",
    "        arg\n",
    "        - source (str) : chemin du dossier\n",
    "        return\n",
    "        - tousleschemins(liste) : liste avec les nom des image dans la source\n",
    "        \"\"\"\n",
    "        tousleschemins: list = []\n",
    "        for fichier in os.listdir(source):\n",
    "            tousleschemins.append(chemin_extraction + fichier)\n",
    "        return tousleschemins\n",
    " \n",
    "    def lirefichier(self, chemin: str)-> str:\n",
    "        \"\"\"ouvre un fichier et transfert son contenue dans une chaine\n",
    "        arg\n",
    "        - chemin (str) : chemin du dossier\n",
    "        return\n",
    "        - contenu_du_fichier (str) : le contenu du fichier\"\"\"\n",
    "        fichier = open(chemin, 'r')\n",
    "        contenu_du_fichier: str = fichier.read()\n",
    "        return contenu_du_fichier\n",
    "    \n",
    "    def ecrirefichier(self, chemin: str, nom: str, contenu: str)-> None:\n",
    "        \"\"\"ecrit un chaine dans un fichier\"\"\"\n",
    "        with open(f\"{chemin}/{nom}.txt\", \"w\", encoding=\"utf-8\") as fichier_sorti:\n",
    "            fichier_sorti.write(contenu)\n",
    "            fichier_sorti.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_source():\n",
    "    \"\"\"chaque article qui servira d'entrée en apprentissage sera mis dans un objet pour analyse, extraction...\"\"\"\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            une chaine de texte (si possible longue)\n",
    "        return :\n",
    "            aucun\n",
    "        \"\"\"\n",
    "        self.texte:str = text #le texte sur lequel on travail\n",
    "        self.dicostatique:dict = {} #pour la fonction liste_et_compte_mots\n",
    "        self.dicodoublons:dict = {} #pour la fonction cherche_binomes_mots - ce qui est recherché\n",
    "    \n",
    "    def retirer_ponctuation(self, txt_a_nettoyer:str) -> str:\n",
    "        \"\"\" La première version du logiciel est sommaire. \n",
    "        Pour se simplifier la vie, il faut supprimer tous les signe de ponctuations.\n",
    "        arg:\n",
    "            une chaine de texte avec de la ponctuation\n",
    "        return:\n",
    "            une chaine de texte sans ponctuation\n",
    "        \"\"\"\n",
    "        ponctuation : list = [\",\",\";\",\":\",\"!\",\"?\",\".\",\"/\",\"«\",\"»\",'\"',\"–\",\"(\",\")\"]\n",
    "        for signe in ponctuation:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(signe, \"\")\n",
    "        #mettre un espace entre les mots avec apostrophe afin de bien les séparer\n",
    "        apostrophe = [\"’\",\"'\"]\n",
    "        for apost in apostrophe:\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(apost, \" \")\n",
    "        #quand on supprime un : par exemple, cela fait deux espace. Remplacer ces artefacts de cagage\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\"  \", \" \")\n",
    "        for _ in range(len(self.texte)):\n",
    "            txt_a_nettoyer = txt_a_nettoyer.replace(\" \", \" \")\n",
    "        return txt_a_nettoyer\n",
    "\n",
    "    def liste_et_compte_mots(self, texte_a_traiter:str) -> list[list,dict]:\n",
    "        \"\"\"Compte le nombre d'occurence d'un mot.\n",
    "        Fonction créée un peu par erreur, mais elle peut être utile pour faire des statistiques.\n",
    "        arg : \n",
    "            texte_a_traiter (str)\n",
    "        return : \n",
    "            2 object dans un liste. La liste des mots de la chaine et le comptrage de chaque mot dans un dictionnaire\n",
    "            \"\"\"\n",
    "        liste_mot: list[str] = texte_a_traiter.split(\" \")\n",
    "        dicostatistique = {}\n",
    "        for mot in liste_mot:\n",
    "            if mot in dicostatistique:\n",
    "                dicostatistique[mot] += 1\n",
    "            else:\n",
    "                dicostatistique[mot] = 1\n",
    "        return [liste_mot, dicostatistique]\n",
    "    \n",
    "    def cherche_binomes_mots(self, texte_a_traiter:str) -> dict:\n",
    "        \"\"\"la fonction principale de l'objet : faire un dictionnaire de fréquences des mots qui se suivent. \n",
    "        arg :\n",
    "            self\n",
    "        return :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "        \"\"\"\n",
    "        liste_mots_suivant:list = []\n",
    "        dicodoublons:dict = {}\n",
    "        #recherche des espaces délimitants les mots\n",
    "        list_position_espace = []\n",
    "        for i in range(len(texte_a_traiter)):\n",
    "            if texte_a_traiter[i] == \" \":\n",
    "                list_position_espace.append(i)\n",
    "        #print(list_position_espace)\n",
    "        #recherche doublons mot\n",
    "        debut1 = 0\n",
    "        for i in range(len(list_position_espace)-2): #AFAIRE : ATTENTION ça ne prends pas les deux derniers mot. A vérifier.\n",
    "            fin1 = list_position_espace[i]\n",
    "            fin2 = list_position_espace[i + 1]\n",
    "            #print(debut1, fin1,fin2)\n",
    "            mot1 = texte_a_traiter[debut1:fin1]\n",
    "            mot2 = texte_a_traiter[fin1:fin2]\n",
    "            debut1 = list_position_espace[i]\n",
    "            #print(mot1,mot2)\n",
    "            liste_mots_suivant.append([mot1, mot2])\n",
    "        #print(liste_mots_suivant)\n",
    "        #fait un dictionnaire avec toutes les occurences possible après un même mot.\n",
    "        #les doublons sont normaux, cela veut dire que le mot revient plusieurs fois, cela correspond au calcul de leur fréquence   \n",
    "        for j in range(len(liste_mots_suivant)):\n",
    "            if liste_mots_suivant[j][0] in dicodoublons.keys():\n",
    "                #print('doublons')\n",
    "                dicodoublons[liste_mots_suivant[j][0]].append(liste_mots_suivant[j][1])\n",
    "            else:\n",
    "                #print('nouveau')\n",
    "                dicodoublons[liste_mots_suivant[j][0]]=[(liste_mots_suivant[j][1])]\n",
    "        # Warning : il y a des espace en trop (tenu en compte pour le reste et tests)\n",
    "        return dicodoublons \n",
    "    \n",
    "    def tout_enchainer(self) -> dict :\n",
    "        self.texte = self.retirer_ponctuation(self.texte)\n",
    "        #self.dicostatique = self.liste_et_compte_mots(self.texte)[1]\n",
    "        #print(self.dicostatique)\n",
    "        #print(\"--------------\")\n",
    "        dicodoublons_txt = self.cherche_binomes_mots(self.texte)\n",
    "        return dicodoublons_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester les méthodes de la classe Article_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from unittest.mock import Mock, patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_analyse():\n",
    "    \n",
    "    def test_retirer_ponctuation(self):\n",
    "        chaine = \"Le, petit chat d'Hercule est mort !\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        retirer = textdebase.retirer_ponctuation(chaine)\n",
    "        assert retirer == \"Le petit chat d Hercule est mort \"\n",
    "        \n",
    "    def test_liste_et_compte_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        list_mot = textdebase.liste_et_compte_mots(chaine)[0]\n",
    "        dico_mot = textdebase.liste_et_compte_mots(chaine)[1]\n",
    "        assert list_mot == ['le','petit','chat','de','béatrice','est','sur','le','petit','mur','du','jardin','de','Yves']\n",
    "        assert dico_mot == {'le':2,'petit':2,'chat':1,'de':2,'béatrice':1,'est':1,'sur':1,'mur':1,'du':1,'jardin':1,'Yves':1}\n",
    "     \n",
    "    \"\"\"  \n",
    "    #code pour tester une erreur dans jupyter \n",
    "    def test_cherche_binomes_mots(self):\n",
    "        chaine = \"le petit chat de béatrice est sur le petit mur du jardin de Yves\"\n",
    "        textdebase = Article_source(chaine)\n",
    "        dico = textdebase.cherche_binomes_mots(chaine)\n",
    "        assert dico == {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeur = Test_modele_analyse()\n",
    "testeur.test_retirer_ponctuation()\n",
    "testeur.test_liste_et_compte_mots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article_au_hasard():\n",
    "    \"\"\"génére un texte aléatoire à partir d'un dictionnaire\n",
    "    \n",
    "        arg :\n",
    "            dictionnaire {mot1:[mot2, mot3, mot3, mot4],...}\n",
    "            typiquement le dictionnaire généré par le return de cherche_binomes_mots(), ou d'une sauvegarde issus de cette fonction.\n",
    "        \n",
    "        return\n",
    "            une chaine de texte avec les mots du dictionnaire dans un ordre aléatoire.\n",
    "            elle pourra aller dans un doc txt pour sauvegarde\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mondico:dict):\n",
    "        \"\"\"initilisation\n",
    "        arg: \n",
    "            mondico (dict) : pour chaque mot en cle dedans, il y a une liste de mot possible.\n",
    "        \"\"\"\n",
    "        self.mondico: dict = mondico #le dictionnaire sur lequel on travail\n",
    "        self.textealeatoire : str =\"\" #le texte que l'on veut\n",
    "    \n",
    "    def choixmotpourcommencer(self, dico: dict)-> str:\n",
    "        \"\"\"a utiliser pour le premier mot, \n",
    "        mais aussi si un mot ne peut pas en trouver d'autre, faire une proposition pour eviter une erreur et continuer\n",
    "        \"\"\"\n",
    "        #Mettre les clefs dans une liste\n",
    "        liste_des_mots : list = []\n",
    "        for key in dico:\n",
    "            liste_des_mots.append(key)\n",
    "        #choix lui meme\n",
    "        mot: str = liste_des_mots[random.randint(0, len(liste_des_mots))]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "\n",
    "    def chercherlemotsuivant(self, dico: dict, mot: str) -> str:\n",
    "        \"\"\"à partir d'un mot, sortir aléatoire un mot dans ceux pouvant le suivre stocké dans le dictionnaire\"\"\"\n",
    "        liste_des_possible: list = dico[\" \" + mot] #WARNING on remet un espace car dans la version du moment, il y a un espace dans le dico et c'est pas bien\n",
    "        mot: str = liste_des_possible[random.randint(0, len(liste_des_possible) -1 )]\n",
    "        #retirer l'espace s'il existe\n",
    "        if mot[0] == \" \":\n",
    "            mot = mot[1:]\n",
    "        return mot      \n",
    "    \n",
    "    def genereruntexte(self, taille_article: int) -> None:\n",
    "        \"\"\"intier avec choixmotpourcommencer(), puis enchainer chercherlemotsuivant()\n",
    "        taille_article est le nombre de mot que l'on veut pour l'article aléatoire\n",
    "        \"\"\"\n",
    "        mot: str = self.choixmotpourcommencer(self.mondico)\n",
    "        self.textealeatoire += mot\n",
    "        for _ in range(taille_article - 1):\n",
    "            new_mot: str = self.chercherlemotsuivant(self.mondico, mot)\n",
    "            mot = new_mot\n",
    "            self.textealeatoire = self.textealeatoire + \" \" + mot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester la class Article_au_hasard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_modele_generation():\n",
    "    \n",
    "    def test_choixmotpourcommencer(self, mocker):\n",
    "        dictionnaire = {' le': [' petit', ' petit'], ' petit':[' chat', ' mur'], ' chat': [' de'], ' de': [' béatrice', ' Yves'], ' béatrice': [' est'],\n",
    "                        ' est': [' sur'], ' sur': [' le'], ' mur': [' du'], ' du': [' jardin'], ' jardin': [' de'], ' Yves': []}\n",
    "        mocker.patch('random.randint', return_value=1)\n",
    "        generation = Article_au_hasard(dictionnaire)\n",
    "        generation.mot = generation.choixmotpourcommencer(dictionnaire)\n",
    "        assert generation.mot == \"petit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'patch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m testeur_article \u001b[38;5;241m=\u001b[39m Test_modele_generation()\n\u001b[0;32m----> 2\u001b[0m testeur_article\u001b[38;5;241m.\u001b[39mtest_choixmotpourcommencer(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mTest_modele_generation.test_choixmotpourcommencer\u001b[0;34m(self, mocker)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_choixmotpourcommencer\u001b[39m(\u001b[38;5;28mself\u001b[39m, mocker):\n\u001b[1;32m      4\u001b[0m     dictionnaire \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m petit\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m chat\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m béatrice\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m est\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m le\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mur\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m du\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m jardin\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m de\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Yves\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m----> 6\u001b[0m     mocker\u001b[38;5;241m.\u001b[39mpatch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom.randint\u001b[39m\u001b[38;5;124m'\u001b[39m, return_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     generation \u001b[38;5;241m=\u001b[39m Article_au_hasard(dictionnaire)\n\u001b[1;32m      8\u001b[0m     generation\u001b[38;5;241m.\u001b[39mmot \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mchoixmotpourcommencer(dictionnaire)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'patch'"
     ]
    }
   ],
   "source": [
    "testeur_article = Test_modele_generation()\n",
    "testeur_article.test_choixmotpourcommencer(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additioner des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_dico(grand_dico : dict, petit_dico : dict)-> dict:\n",
    "    \"\"\"Permet de mettre le contenu d'un dictionnaire dans un autre.\n",
    "    Si dans les deux dic, il y a une clef commune, il concatène les deux listes de mot\n",
    "    \"\"\"\n",
    "    for keys, values in petit_dico.items():\n",
    "        if keys in grand_dico:\n",
    "            liste_intermediaire = grand_dico[keys]\n",
    "            for item in values:\n",
    "                liste_intermediaire.append(item)\n",
    "            grand_dico[keys] = liste_intermediaire\n",
    "        else:\n",
    "            grand_dico[keys] = values\n",
    "    return grand_dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tester l'addition de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_addition_dico():\n",
    "    dico1 = {'a' : ['le', 'petit'], 'b' : ['chat', 'de']}\n",
    "    dico2 = {'b' : ['de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    dico3 = addition_dico(dico1, dico2)\n",
    "    assert dico3 == {'a' : ['le', 'petit'], 'b' : ['chat', 'de', 'de', 'yves'], 'c' : ['dans', 'jardin']}\n",
    "    \n",
    "test_addition_dico()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser tous les fichiers d'un dossier et en faire un dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_dossier_et_faire_dico(source : str) -> dict:\n",
    "    \"\"\"Pour tous les fichiers d'un dossier, \n",
    "    lire le contenue, en faire le dictionnaire \n",
    "    et fusionner tous les dictionnaire en un seul.\n",
    "    arg:\n",
    "    - source (str) : chemin d'un dossier\n",
    "    return:\n",
    "    - dict_statistique (dict)\n",
    "    \"\"\"\n",
    "    gestionnaire = Gestionfichier()\n",
    "    lesfichichiers = gestionnaire.lister_fichier(source)\n",
    "    #print(lesfichichiers)\n",
    "    dict_statistique = {}\n",
    "    for item in lesfichichiers:\n",
    "        contenu_a_analyser = gestionnaire.lirefichier(item)\n",
    "        analyseur = Article_source(contenu_a_analyser)\n",
    "        dico_item = analyseur.tout_enchainer()\n",
    "        dict_statistique = addition_dico(dict_statistique, dico_item)\n",
    "    return dict_statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfin, générer notre article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des fichiers de 'vrai_texte/wikipedia', génére un texte de 250 mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou_sont_les_sources = \"vrai_texte/wikipedia\"\n",
    "#ou_sont_les_sources = \"vrai_texte/hft\"\n",
    "ou_sont_les_sources : str = \"vrai_texte/tout\"\n",
    "nb_mot_article : int = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3967a89aa2724141b16a15d7a53118bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=250, description=\"Combien de mot doit faire l'article ?\", layout=Layout(height='50px', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "\n",
    "choix_nb_mot = widgets.BoundedIntText(\n",
    "    value = 250,min = 100,max = 1000, step = 1,\n",
    "    description = \"Combien de mot doit faire l'article ?\", style = style, \n",
    "    disabled = False,\n",
    "    continuous_update = False,\n",
    "    readout = True,\n",
    "    width = '25%', height = '160px',\n",
    "    layout = widgets.Layout(width = '100%', height = '50px'))\n",
    "\n",
    "display(choix_nb_mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mot_article = choix_nb_mot.value\n",
    "nb_mot_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# préparer le dictionnaire qui pourra être réutilisé plusieurs fois\n",
    "superdico = analyser_dossier_et_faire_dico(ou_sont_les_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation() -> None :\n",
    "    redacteur = Article_au_hasard(superdico)\n",
    "    redacteur.genereruntexte(nb_mot_article)\n",
    "    article_aleatoire_redige = redacteur.textealeatoire\n",
    "    return article_aleatoire_redige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Article_au_hasard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cellule à exécuter pour un nouveau texte\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m article_obtenue \u001b[38;5;241m=\u001b[39m generation()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(article_obtenue)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36mgeneration\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgeneration\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m :\n\u001b[0;32m----> 2\u001b[0m     redacteur \u001b[38;5;241m=\u001b[39m Article_au_hasard(superdico)\n\u001b[1;32m      3\u001b[0m     redacteur\u001b[38;5;241m.\u001b[39mgenereruntexte(nb_mot_article)\n\u001b[1;32m      4\u001b[0m     article_aleatoire_redige \u001b[38;5;241m=\u001b[39m redacteur\u001b[38;5;241m.\u001b[39mtextealeatoire\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Article_au_hasard' is not defined"
     ]
    }
   ],
   "source": [
    "# Cellule à exécuter pour un nouveau texte\n",
    "article_obtenue = generation()\n",
    "print(article_obtenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour horodater le fichier\n",
    "def horodatage():\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d%H%M%S%f\") #A la micro-seconde prêt \n",
    "    return timestamp\n",
    "    # print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoir_un_fichier()-> None:\n",
    "    ecrivain = Gestionfichier()\n",
    "    ecrivain.ecrirefichier(\"./textes_generes\", str(horodatage()), article_obtenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoir_un_fichier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe3de1a0e7409a2ccc6de6192b3efb31b2ffd52a0bbf7c80c998e5faa22bb788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
